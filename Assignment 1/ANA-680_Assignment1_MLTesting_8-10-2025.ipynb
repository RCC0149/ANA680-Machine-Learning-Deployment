{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896dac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Default Model Results ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcc_0\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\rcc_0\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\rcc_0\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Accuracy        F1   ROC-AUC\n",
      "LogisticRegression  0.960000  0.936937  0.996729\n",
      "KNN                 0.960000  0.936937  0.996432\n",
      "LinearSVM           0.960000  0.936937  0.996878\n",
      "KernelSVM           0.971429  0.955752  0.996729\n",
      "NaiveBayes          0.960000  0.940171  0.162504\n",
      "DecisionTree        0.954286  0.929825  0.500000\n",
      "RandomForest        0.954286  0.929825  0.500000\n",
      "XGBoost             0.942857  0.909091  0.993904\n",
      "\n",
      "=== Parameter Tuning ===\n",
      "LogisticRegression Best Params: {'C': 0.0004, 'max_iter': 65, 'solver': 'liblinear'}\n",
      "KNN Best Params: {'algorithm': 'auto', 'metric': 'euclidean', 'p': 1, 'weights': 'uniform'}\n",
      "LinearSVM Best Params: {'C': 0.005, 'max_iter': 155}\n",
      "KernelSVM Best Params: {'C': 1.75, 'gamma': 'scale'}\n",
      "NaiveBayes Best Params: {'var_smoothing': 1e-09}\n",
      "DecisionTree Best Params: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "RandomForest Best Params: {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "XGBoost Best Params: {'colsample_bytree': 0.1, 'gamma': 0, 'learning_rate': 0.08, 'max_depth': 3, 'n_estimators': 49, 'reg_alpha': 0, 'reg_lambda': 0, 'subsample': 0.8}\n",
      "\n",
      "=== Tuned Model Results ===\n",
      "                    Accuracy        F1   ROC-AUC\n",
      "LogisticRegression  0.960000  0.939130  0.996432\n",
      "KNN                 0.960000  0.936937  0.996432\n",
      "LinearSVM           0.965714  0.947368  0.996580\n",
      "KernelSVM           0.960000  0.939130  0.995688\n",
      "NaiveBayes          0.960000  0.940171  0.992417\n",
      "DecisionTree        0.948571  0.920354  0.653657\n",
      "RandomForest        0.960000  0.941176  0.552632\n",
      "XGBoost             0.977143  0.965517  0.995391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcc_0\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\rcc_0\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load and prep data\n",
    "df = pd.read_csv('breast-cancer-wisconsin_cleaned.csv', header=0)\n",
    "features = [str(i) for i in range(1, 10)]  # Features 1 through 9 (string indices '1' to '9')\n",
    "X = df[features]\n",
    "y = df['10']  # Feature 10 (index 10) as target, already binary (0 and 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 1: Default model results\n",
    "print(\"=== Default Model Results ===\")\n",
    "default_models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'LinearSVM': SVC(kernel='linear', random_state=42, probability=True),\n",
    "    'KernelSVM': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, n_estimators=10),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "default_results = {}\n",
    "for name, model in default_models.items():\n",
    "    model.fit(X_train_scaled if name in ['LogisticRegression', 'KNN', 'LinearSVM', 'KernelSVM', 'XGBoost'] else X_train, y_train)\n",
    "    y_pred = model.predict(X_test_scaled if name in ['LogisticRegression', 'KNN', 'LinearSVM', 'KernelSVM', 'XGBoost'] else X_test)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    default_results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_prob) if y_prob is not None else 'N/A'\n",
    "    }\n",
    "print(pd.DataFrame(default_results).T)\n",
    "\n",
    "# Step 2: Parameter tuning with GridSearchCV (F1 scoring)\n",
    "print(\"\\n=== Parameter Tuning ===\")\n",
    "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train) if sum(y_train) > 0 else 1.0  # Handle potential zero positives\n",
    "\n",
    "tuning_models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "        'params': {'C': [0.0004], 'max_iter': [65], 'solver': ['lbfgs', 'liblinear']}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(n_neighbors=5),\n",
    "        'params': {'weights': ['uniform'], 'metric': ['euclidean'], 'p': [1], 'algorithm': ['auto']}\n",
    "    },\n",
    "    'LinearSVM': {\n",
    "        'model': SVC(kernel='linear', random_state=42, probability=True, class_weight='balanced'),\n",
    "        'params': {'C': [0.005], 'max_iter': [155]}\n",
    "    },\n",
    "    'KernelSVM': {\n",
    "        'model': SVC(kernel='rbf', random_state=42, probability=True, class_weight='balanced'),\n",
    "        'params': {'C': [1.75], 'gamma': ['scale']}\n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {'var_smoothing': [1e-9]}\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "        'params': {'max_depth': [None], 'min_samples_split': [2], 'min_samples_leaf': [2], 'criterion': ['entropy'], 'max_leaf_nodes': [None], 'min_impurity_decrease': [0.0]}\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=10),\n",
    "        'params': {'max_depth': [5], 'min_samples_split': [2], 'min_samples_leaf': [2], 'max_features': ['sqrt'], 'bootstrap': [True]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight),\n",
    "        'params': {'n_estimators': [49], 'max_depth': [3], 'learning_rate': [0.08], 'colsample_bytree': [0.1], 'subsample': [0.8], 'gamma': [0], 'reg_alpha': [0], 'reg_lambda': [0]}\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, info in tuning_models.items():\n",
    "    grid = GridSearchCV(info['model'], info['params'], cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid.fit(X_train_scaled if name in ['LogisticRegression', 'KNN', 'LinearSVM', 'KernelSVM', 'NaiveBayes', 'XGBoost'] else X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(f\"{name} Best Params: {grid.best_params_}\")\n",
    "\n",
    "# Step 3: Rerun with tuned models\n",
    "print(\"\\n=== Tuned Model Results ===\")\n",
    "tuned_results = {}\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test_scaled if name in ['LogisticRegression', 'KNN', 'LinearSVM', 'KernelSVM', 'NaiveBayes', 'XGBoost'] else X_test)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    tuned_results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_prob) if y_prob is not None else 'N/A'\n",
    "    }\n",
    "print(pd.DataFrame(tuned_results).T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
