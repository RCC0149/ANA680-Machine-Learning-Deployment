{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c5928bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcc_0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.1881 - val_accuracy: 0.7775 - val_loss: 0.4570\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.1720 - val_accuracy: 0.7563 - val_loss: 0.4976\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7422 - loss: 0.1668 - val_accuracy: 0.7650 - val_loss: 0.4795\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7619 - loss: 0.1627 - val_accuracy: 0.7775 - val_loss: 0.4716\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7634 - loss: 0.1614 - val_accuracy: 0.7806 - val_loss: 0.4909\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.1606 - val_accuracy: 0.8069 - val_loss: 0.4489\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7714 - loss: 0.1585 - val_accuracy: 0.7887 - val_loss: 0.5006\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.1589 - val_accuracy: 0.7975 - val_loss: 0.4507\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7719 - loss: 0.1574 - val_accuracy: 0.7719 - val_loss: 0.4807\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.1579 - val_accuracy: 0.7794 - val_loss: 0.4826\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.1582 - val_accuracy: 0.7600 - val_loss: 0.5032\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7772 - loss: 0.1575 - val_accuracy: 0.7975 - val_loss: 0.4606\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.1581 - val_accuracy: 0.7912 - val_loss: 0.4563\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7817 - loss: 0.1576 - val_accuracy: 0.7688 - val_loss: 0.4788\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.1559 - val_accuracy: 0.7850 - val_loss: 0.4460\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.1567 - val_accuracy: 0.7750 - val_loss: 0.4997\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7723 - loss: 0.1572 - val_accuracy: 0.7706 - val_loss: 0.4734\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.1558 - val_accuracy: 0.7513 - val_loss: 0.5096\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.1582 - val_accuracy: 0.7669 - val_loss: 0.4754\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7719 - loss: 0.1582 - val_accuracy: 0.7806 - val_loss: 0.4595\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.1559 - val_accuracy: 0.7581 - val_loss: 0.5228\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7728 - loss: 0.1559 - val_accuracy: 0.7800 - val_loss: 0.4564\n",
      "Epoch 23/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7723 - loss: 0.1571 - val_accuracy: 0.7644 - val_loss: 0.4964\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.1569 - val_accuracy: 0.7763 - val_loss: 0.4641\n",
      "Epoch 25/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.1570 - val_accuracy: 0.7975 - val_loss: 0.4412\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.1579 - val_accuracy: 0.7769 - val_loss: 0.4661\n",
      "Epoch 27/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 0.1570 - val_accuracy: 0.7925 - val_loss: 0.4460\n",
      "Epoch 28/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7883 - loss: 0.1553 - val_accuracy: 0.7669 - val_loss: 0.4774\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.1579 - val_accuracy: 0.8069 - val_loss: 0.4370\n",
      "Epoch 30/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7809 - loss: 0.1575 - val_accuracy: 0.7825 - val_loss: 0.4451\n",
      "Epoch 31/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7836 - loss: 0.1544 - val_accuracy: 0.7719 - val_loss: 0.4670\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7828 - loss: 0.1558 - val_accuracy: 0.7837 - val_loss: 0.4405\n",
      "Epoch 33/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.1569 - val_accuracy: 0.7706 - val_loss: 0.4664\n",
      "Epoch 34/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7773 - loss: 0.1559 - val_accuracy: 0.7656 - val_loss: 0.4679\n",
      "Epoch 35/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.1550 - val_accuracy: 0.7625 - val_loss: 0.4618\n",
      "Epoch 36/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.1554 - val_accuracy: 0.7750 - val_loss: 0.4563\n",
      "Epoch 37/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.1556 - val_accuracy: 0.8069 - val_loss: 0.4310\n",
      "Epoch 38/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7755 - loss: 0.1538 - val_accuracy: 0.7819 - val_loss: 0.4624\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.1569 - val_accuracy: 0.7644 - val_loss: 0.4856\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.1559 - val_accuracy: 0.7788 - val_loss: 0.4599\n",
      "Epoch 41/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7828 - loss: 0.1585 - val_accuracy: 0.7625 - val_loss: 0.4655\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.1555 - val_accuracy: 0.7575 - val_loss: 0.4894\n",
      "Epoch 43/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7727 - loss: 0.1554 - val_accuracy: 0.7869 - val_loss: 0.4512\n",
      "Epoch 44/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.1560 - val_accuracy: 0.7725 - val_loss: 0.4664\n",
      "Epoch 45/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.1551 - val_accuracy: 0.7613 - val_loss: 0.4812\n",
      "Epoch 46/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.1551 - val_accuracy: 0.7925 - val_loss: 0.4239\n",
      "Epoch 47/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7758 - loss: 0.1553 - val_accuracy: 0.7631 - val_loss: 0.4790\n",
      "Epoch 48/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.1571 - val_accuracy: 0.7600 - val_loss: 0.4889\n",
      "Epoch 49/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.1541 - val_accuracy: 0.7669 - val_loss: 0.4633\n",
      "Epoch 50/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.1552 - val_accuracy: 0.7769 - val_loss: 0.4688\n",
      "Epoch 51/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7681 - loss: 0.1555 - val_accuracy: 0.7937 - val_loss: 0.4351\n",
      "Epoch 52/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.1544 - val_accuracy: 0.7800 - val_loss: 0.4535\n",
      "Epoch 53/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.1570 - val_accuracy: 0.7744 - val_loss: 0.4590\n",
      "Epoch 54/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7795 - loss: 0.1561 - val_accuracy: 0.7700 - val_loss: 0.4582\n",
      "Epoch 55/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7773 - loss: 0.1537 - val_accuracy: 0.7538 - val_loss: 0.4846\n",
      "Epoch 56/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7713 - loss: 0.1545 - val_accuracy: 0.7513 - val_loss: 0.4940\n",
      "Epoch 57/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.1555 - val_accuracy: 0.7550 - val_loss: 0.4855\n",
      "Epoch 58/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.1543 - val_accuracy: 0.7613 - val_loss: 0.4709\n",
      "Epoch 59/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.1551 - val_accuracy: 0.7688 - val_loss: 0.4614\n",
      "Epoch 60/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.1547 - val_accuracy: 0.7506 - val_loss: 0.4729\n",
      "Epoch 61/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.1532 - val_accuracy: 0.7663 - val_loss: 0.4486\n",
      "Epoch 62/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.1553 - val_accuracy: 0.7594 - val_loss: 0.4712\n",
      "Epoch 63/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.1558 - val_accuracy: 0.7881 - val_loss: 0.4402\n",
      "Epoch 64/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7708 - loss: 0.1558 - val_accuracy: 0.7744 - val_loss: 0.4474\n",
      "Epoch 65/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7753 - loss: 0.1546 - val_accuracy: 0.7400 - val_loss: 0.4976\n",
      "Epoch 66/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7659 - loss: 0.1544 - val_accuracy: 0.7962 - val_loss: 0.4410\n",
      "Epoch 67/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7736 - loss: 0.1546 - val_accuracy: 0.7794 - val_loss: 0.4387\n",
      "Epoch 68/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.1563 - val_accuracy: 0.7506 - val_loss: 0.4970\n",
      "Epoch 69/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7772 - loss: 0.1531 - val_accuracy: 0.7919 - val_loss: 0.4386\n",
      "Epoch 70/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7755 - loss: 0.1587 - val_accuracy: 0.7800 - val_loss: 0.4581\n",
      "Epoch 71/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7745 - loss: 0.1544 - val_accuracy: 0.7700 - val_loss: 0.4664\n",
      "Epoch 72/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7744 - loss: 0.1542 - val_accuracy: 0.7925 - val_loss: 0.4228\n",
      "Epoch 73/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7719 - loss: 0.1545 - val_accuracy: 0.7806 - val_loss: 0.4325\n",
      "Epoch 74/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.1548 - val_accuracy: 0.7606 - val_loss: 0.4619\n",
      "Epoch 75/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.1539 - val_accuracy: 0.7738 - val_loss: 0.4488\n",
      "Epoch 76/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.1551 - val_accuracy: 0.7663 - val_loss: 0.4683\n",
      "Epoch 77/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.1561 - val_accuracy: 0.7681 - val_loss: 0.4580\n",
      "Epoch 78/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.1530 - val_accuracy: 0.7769 - val_loss: 0.4504\n",
      "Epoch 79/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7822 - loss: 0.1547 - val_accuracy: 0.7800 - val_loss: 0.4600\n",
      "Epoch 80/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7773 - loss: 0.1555 - val_accuracy: 0.7956 - val_loss: 0.4340\n",
      "Epoch 81/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.1550 - val_accuracy: 0.7800 - val_loss: 0.4546\n",
      "Epoch 82/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7856 - loss: 0.1559 - val_accuracy: 0.7925 - val_loss: 0.4488\n",
      "Epoch 83/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7761 - loss: 0.1554 - val_accuracy: 0.7775 - val_loss: 0.4523\n",
      "Epoch 84/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7778 - loss: 0.1548 - val_accuracy: 0.7850 - val_loss: 0.4735\n",
      "Epoch 85/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.1548 - val_accuracy: 0.7663 - val_loss: 0.4807\n",
      "Epoch 86/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7789 - loss: 0.1536 - val_accuracy: 0.7956 - val_loss: 0.4536\n",
      "Epoch 87/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.1551 - val_accuracy: 0.7675 - val_loss: 0.4813\n",
      "Epoch 88/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.1557 - val_accuracy: 0.7744 - val_loss: 0.4944\n",
      "Epoch 89/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.1537 - val_accuracy: 0.7919 - val_loss: 0.4360\n",
      "Epoch 90/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.1581 - val_accuracy: 0.7581 - val_loss: 0.5106\n",
      "Epoch 91/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.1546 - val_accuracy: 0.7738 - val_loss: 0.4598\n",
      "Epoch 92/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 0.1560 - val_accuracy: 0.7656 - val_loss: 0.4731\n",
      "Epoch 93/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.1539 - val_accuracy: 0.7806 - val_loss: 0.4611\n",
      "Epoch 94/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.1554 - val_accuracy: 0.7800 - val_loss: 0.4399\n",
      "Epoch 95/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.1558 - val_accuracy: 0.7744 - val_loss: 0.4643\n",
      "Epoch 96/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.1542 - val_accuracy: 0.7794 - val_loss: 0.4517\n",
      "Epoch 97/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.1535 - val_accuracy: 0.7750 - val_loss: 0.4541\n",
      "Epoch 98/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7703 - loss: 0.1565 - val_accuracy: 0.7694 - val_loss: 0.4678\n",
      "Epoch 99/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.1538 - val_accuracy: 0.7581 - val_loss: 0.4782\n",
      "Epoch 100/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7680 - loss: 0.1550 - val_accuracy: 0.7638 - val_loss: 0.4896\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Optimal Threshold (based on max F1-Score): 0.623\n",
      "\n",
      "Confusion Matrix:\n",
      "                   Predicted Stayed (0)  Predicted Left (1)\n",
      "Actual Stayed (0)                  1429                 166\n",
      "Actual Left (1)                     136                 269\n",
      "\n",
      "Accuracy: 0.849\n",
      "Precision: 0.618\n",
      "Recall: 0.664\n",
      "F1-Score: 0.640\n",
      "ROC-AUC: 0.780\n",
      "Specificity: 0.896\n",
      "PR-AUC: 0.502\n",
      "\n",
      "Threshold Table [0.1 - 0.9]:\n",
      " Threshold  Precision  Recall  F1-Score\n",
      "       0.1      0.252   0.980     0.401\n",
      "       0.2      0.313   0.960     0.472\n",
      "       0.3      0.369   0.901     0.524\n",
      "       0.4      0.410   0.852     0.554\n",
      "       0.5      0.469   0.793     0.589\n",
      "       0.6      0.618   0.664     0.640\n",
      "       0.7      0.681   0.570     0.621\n",
      "       0.8      0.808   0.457     0.584\n",
      "       0.9      0.897   0.257     0.399\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('Churn_Modeling_cleaned.csv')\n",
    "\n",
    "# Select significant features based on EDA correlation analysis\n",
    "significant_features = ['NumOfProducts_2', 'Age', 'NumOfProducts_3', 'Geography_Germany', \n",
    "                       'IsActiveMember', 'NumOfProducts_4', 'ZeroBalance', 'Balance', 'Gender']\n",
    "X = dataset[significant_features]\n",
    "y = dataset['Exited'].values\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Set hyperparameters (adjustable based on your best results)\n",
    "units_per_layer = 12  # Your best: 12 units\n",
    "num_hidden_layers = 2  # Fixed to 2 layers (no option for 3)\n",
    "dropout_rate = 0.25  # Your best: 0.15 dropout\n",
    "learning_rate = 0.007  # Your best: 0.1 learning rate\n",
    "batch_size = 32  # Your best: 32 batch size\n",
    "patience = 30  # Your best: 10 patience\n",
    "max_epochs = 100  # Your best: 100 epochs\n",
    "validation_split = 0.2  # Your best: assumed v_split=2 was a typo for 0.2\n",
    "\n",
    "# Build the ANN with 2 hidden layers maximum\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=units_per_layer, activation='relu', input_dim=X_train.shape[1]))  # First hidden layer\n",
    "classifier.add(Dropout(dropout_rate))  # Dropout after first hidden layer\n",
    "classifier.add(Dense(units=units_per_layer, activation='relu'))  # Second hidden layer\n",
    "classifier.add(Dropout(dropout_rate))  # Dropout after second hidden layer\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# Set custom learning rate for Adam optimizer\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the ANN with class weights and custom optimizer\n",
    "class_weight = {0: 1 / 7963, 1: 1 / 2037}  # Inverse frequency weights\n",
    "total = 1 / 7963 + 1 / 2037\n",
    "class_weight = {0: (1 / 7963) / total, 1: (1 / 2037) / total}  # Normalize\n",
    "classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "# Train the ANN with EarlyStopping and validation split\n",
    "classifier.fit(X_train, y_train, batch_size=batch_size, epochs=max_epochs, class_weight=class_weight, \n",
    "               validation_split=validation_split, callbacks=[early_stopping])\n",
    "\n",
    "# Predict on the test set (probabilities)\n",
    "y_pred_prob = classifier.predict(X_test)\n",
    "\n",
    "# Precision-Recall Curve for threshold optimization\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)  # Avoid division by zero\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Print optimal threshold with 3 decimal places\n",
    "print(f\"Optimal Threshold (based on max F1-Score): {optimal_threshold:.3f}\")\n",
    "\n",
    "# Set the threshold here (edit this value to test different thresholds, e.g., 0.5 or optimal_threshold)\n",
    "custom_threshold = 0.6  # Default set to optimal_threshold; change to any value between 0 and 1\n",
    "\n",
    "# Apply the custom threshold\n",
    "y_pred = (y_pred_prob > custom_threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "pr_auc = np.trapezoid(recall, precision)  # Using trapezoid instead of trapz\n",
    "\n",
    "# Display Confusion Matrix as a table (copy-paste compatible for Word)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_table = pd.DataFrame(cm, index=['Actual Stayed (0)', 'Actual Left (1)'], columns=['Predicted Stayed (0)', 'Predicted Left (1)'])\n",
    "print(cm_table.to_string())\n",
    "\n",
    "# Print metrics with 3 decimal places\n",
    "print(f\"\\nAccuracy: {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall: {rec:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"Specificity: {spec:.3f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.3f}\")\n",
    "\n",
    "# Display Threshold Table for 0.1 to 0.9 (copy-paste compatible for Word)\n",
    "print(\"\\nThreshold Table [0.1 - 0.9]:\")\n",
    "thresholds_table = []\n",
    "for thresh in np.arange(0.1, 1.0, 0.1):\n",
    "    y_pred_thresh = (y_pred_prob > thresh).astype(int)\n",
    "    prec_thresh = precision_score(y_test, y_pred_thresh)\n",
    "    rec_thresh = recall_score(y_test, y_pred_thresh)\n",
    "    f1_thresh = f1_score(y_test, y_pred_thresh)\n",
    "    thresholds_table.append([thresh, prec_thresh, rec_thresh, f1_thresh])\n",
    "\n",
    "thresholds_df = pd.DataFrame(thresholds_table, columns=['Threshold', 'Precision', 'Recall', 'F1-Score'])\n",
    "thresholds_df = thresholds_df.round(3)  # Round to 3 decimal places\n",
    "print(thresholds_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 (Global .venv)",
   "language": "python",
   "name": "global_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
