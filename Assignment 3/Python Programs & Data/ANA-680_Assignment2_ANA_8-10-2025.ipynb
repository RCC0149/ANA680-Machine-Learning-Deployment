{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c5928bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcc_0\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.2105 - val_accuracy: 0.7181 - val_loss: 0.5247\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.1702 - val_accuracy: 0.7500 - val_loss: 0.5105\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.1701 - val_accuracy: 0.7394 - val_loss: 0.4938\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7425 - loss: 0.1664 - val_accuracy: 0.7613 - val_loss: 0.4955\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7482 - loss: 0.1668 - val_accuracy: 0.7606 - val_loss: 0.4980\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7524 - loss: 0.1653 - val_accuracy: 0.7800 - val_loss: 0.4579\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7797 - loss: 0.1579 - val_accuracy: 0.7925 - val_loss: 0.4506\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.1606 - val_accuracy: 0.7894 - val_loss: 0.4765\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7685 - loss: 0.1602 - val_accuracy: 0.7900 - val_loss: 0.4742\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: 0.1561 - val_accuracy: 0.7756 - val_loss: 0.5029\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7898 - loss: 0.1556 - val_accuracy: 0.7763 - val_loss: 0.4948\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.1579 - val_accuracy: 0.8037 - val_loss: 0.4789\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.1540 - val_accuracy: 0.8075 - val_loss: 0.4561\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7885 - loss: 0.1615 - val_accuracy: 0.7975 - val_loss: 0.4815\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.1551 - val_accuracy: 0.8106 - val_loss: 0.4647\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.1615 - val_accuracy: 0.8069 - val_loss: 0.4424\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7902 - loss: 0.1590 - val_accuracy: 0.7875 - val_loss: 0.4668\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7920 - loss: 0.1544 - val_accuracy: 0.8056 - val_loss: 0.4602\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.1594 - val_accuracy: 0.8069 - val_loss: 0.4429\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8032 - loss: 0.1551 - val_accuracy: 0.8125 - val_loss: 0.4553\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.1557 - val_accuracy: 0.7887 - val_loss: 0.4337\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7803 - loss: 0.1549 - val_accuracy: 0.7731 - val_loss: 0.4802\n",
      "Epoch 23/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7756 - loss: 0.1593 - val_accuracy: 0.8012 - val_loss: 0.4430\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.1504 - val_accuracy: 0.8037 - val_loss: 0.4427\n",
      "Epoch 25/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7881 - loss: 0.1538 - val_accuracy: 0.7844 - val_loss: 0.4748\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7906 - loss: 0.1507 - val_accuracy: 0.7794 - val_loss: 0.4964\n",
      "Epoch 27/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.1578 - val_accuracy: 0.7669 - val_loss: 0.4922\n",
      "Epoch 28/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.1538 - val_accuracy: 0.8012 - val_loss: 0.4497\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.1591 - val_accuracy: 0.8087 - val_loss: 0.4731\n",
      "Epoch 30/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.1521 - val_accuracy: 0.8119 - val_loss: 0.4571\n",
      "Epoch 31/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.1563 - val_accuracy: 0.8062 - val_loss: 0.4515\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.1503 - val_accuracy: 0.8044 - val_loss: 0.4392\n",
      "Epoch 33/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7909 - loss: 0.1546 - val_accuracy: 0.7675 - val_loss: 0.4604\n",
      "Epoch 34/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.1560 - val_accuracy: 0.7763 - val_loss: 0.4718\n",
      "Epoch 35/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.1536 - val_accuracy: 0.7794 - val_loss: 0.4657\n",
      "Epoch 36/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7981 - loss: 0.1534 - val_accuracy: 0.7906 - val_loss: 0.4534\n",
      "Epoch 37/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8058 - loss: 0.1544 - val_accuracy: 0.8087 - val_loss: 0.4489\n",
      "Epoch 38/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.1511 - val_accuracy: 0.7594 - val_loss: 0.4691\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.1626 - val_accuracy: 0.8163 - val_loss: 0.4162\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.1607 - val_accuracy: 0.8050 - val_loss: 0.4549\n",
      "Epoch 41/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.1524 - val_accuracy: 0.8062 - val_loss: 0.4597\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.1530 - val_accuracy: 0.8163 - val_loss: 0.4554\n",
      "Epoch 43/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.1512 - val_accuracy: 0.8019 - val_loss: 0.4657\n",
      "Epoch 44/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.1522 - val_accuracy: 0.7975 - val_loss: 0.4631\n",
      "Epoch 45/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.1547 - val_accuracy: 0.8025 - val_loss: 0.4496\n",
      "Epoch 46/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8040 - loss: 0.1522 - val_accuracy: 0.7994 - val_loss: 0.4730\n",
      "Epoch 47/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.1550 - val_accuracy: 0.7831 - val_loss: 0.4671\n",
      "Epoch 48/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8040 - loss: 0.1481 - val_accuracy: 0.7950 - val_loss: 0.4667\n",
      "Epoch 49/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7848 - loss: 0.1586 - val_accuracy: 0.7769 - val_loss: 0.4858\n",
      "Epoch 50/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7832 - loss: 0.1600 - val_accuracy: 0.7725 - val_loss: 0.5009\n",
      "Epoch 51/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.1503 - val_accuracy: 0.7969 - val_loss: 0.4363\n",
      "Epoch 52/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.1505 - val_accuracy: 0.7962 - val_loss: 0.4440\n",
      "Epoch 53/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.1527 - val_accuracy: 0.8056 - val_loss: 0.4351\n",
      "Epoch 54/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7932 - loss: 0.1577 - val_accuracy: 0.7969 - val_loss: 0.4619\n",
      "Epoch 55/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.1502 - val_accuracy: 0.7969 - val_loss: 0.4686\n",
      "Epoch 56/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.1532 - val_accuracy: 0.7906 - val_loss: 0.4834\n",
      "Epoch 57/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.1523 - val_accuracy: 0.7931 - val_loss: 0.4603\n",
      "Epoch 58/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.1557 - val_accuracy: 0.7812 - val_loss: 0.4949\n",
      "Epoch 59/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7912 - loss: 0.1519 - val_accuracy: 0.8081 - val_loss: 0.4720\n",
      "Epoch 60/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.1557 - val_accuracy: 0.8081 - val_loss: 0.4454\n",
      "Epoch 61/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.1533 - val_accuracy: 0.8044 - val_loss: 0.4430\n",
      "Epoch 62/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.1504 - val_accuracy: 0.7638 - val_loss: 0.5069\n",
      "Epoch 63/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7787 - loss: 0.1563 - val_accuracy: 0.7887 - val_loss: 0.4461\n",
      "Epoch 64/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7858 - loss: 0.1530 - val_accuracy: 0.7881 - val_loss: 0.4789\n",
      "Epoch 65/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8007 - loss: 0.1503 - val_accuracy: 0.7887 - val_loss: 0.4598\n",
      "Epoch 66/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7955 - loss: 0.1492 - val_accuracy: 0.8069 - val_loss: 0.4315\n",
      "Epoch 67/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.1508 - val_accuracy: 0.7919 - val_loss: 0.4754\n",
      "Epoch 68/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.1529 - val_accuracy: 0.7981 - val_loss: 0.4594\n",
      "Epoch 69/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.1548 - val_accuracy: 0.8075 - val_loss: 0.4309\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Optimal Threshold (based on max F1-Score): 0.612\n",
      "\n",
      "Confusion Matrix:\n",
      "                   Predicted Stayed (0)  Predicted Left (1)\n",
      "Actual Stayed (0)                  1460                 135\n",
      "Actual Left (1)                     155                 250\n",
      "\n",
      "Accuracy: 0.855\n",
      "Precision: 0.649\n",
      "Recall: 0.617\n",
      "F1-Score: 0.633\n",
      "ROC-AUC: 0.766\n",
      "Specificity: 0.915\n",
      "PR-AUC: 0.488\n",
      "\n",
      "Threshold Table [0.1 - 0.9]:\n",
      " Threshold  Precision  Recall  F1-Score\n",
      "       0.1      0.278   0.970     0.433\n",
      "       0.2      0.314   0.946     0.472\n",
      "       0.3      0.372   0.894     0.526\n",
      "       0.4      0.443   0.832     0.578\n",
      "       0.5      0.528   0.743     0.617\n",
      "       0.6      0.649   0.617     0.633\n",
      "       0.7      0.694   0.548     0.612\n",
      "       0.8      0.776   0.437     0.559\n",
      "       0.9      0.889   0.237     0.374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('Churn_Modeling.csv')\n",
    "\n",
    "# Add new feature: ZeroBalance\n",
    "dataset['ZeroBalance'] = (dataset['Balance'] == 0).astype(int)\n",
    "\n",
    "# Select features (excluding irrelevant columns: RowNumber, CustomerId, Surname)\n",
    "X = dataset.drop(['RowNumber', 'CustomerId', 'Surname', 'Exited'], axis=1)\n",
    "y = dataset['Exited'].values\n",
    "\n",
    "# Encode categorical data\n",
    "# Gender: Label encoding (binary)\n",
    "le = LabelEncoder()\n",
    "X['Gender'] = le.fit_transform(X['Gender'])\n",
    "\n",
    "# Geography and NumOfProducts: One-hot encoding\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder_geo', OneHotEncoder(), ['Geography']),\n",
    "        ('encoder_prod', OneHotEncoder(), ['NumOfProducts'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Set hyperparameters (adjustable based on your best results)\n",
    "units_per_layer = 12  # Your best: 12 units\n",
    "num_hidden_layers = 2  # Fixed to 2 layers (no option for 3)\n",
    "dropout_rate = 0.25  # Your best: 0.15 dropout\n",
    "learning_rate = 0.007  # Your best: 0.1 learning rate\n",
    "batch_size = 32  # Your best: 32 batch size\n",
    "patience = 30  # Your best: 10 patience\n",
    "max_epochs = 100  # Your best: 100 epochs\n",
    "validation_split = 0.2  # Your best: assumed v_split=2 was a typo for 0.2\n",
    "\n",
    "# Build the ANN with 2 hidden layers maximum\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=units_per_layer, activation='relu', input_dim=X_train.shape[1]))  # First hidden layer\n",
    "classifier.add(Dropout(dropout_rate))  # Dropout after first hidden layer\n",
    "classifier.add(Dense(units=units_per_layer, activation='relu'))  # Second hidden layer\n",
    "classifier.add(Dropout(dropout_rate))  # Dropout after second hidden layer\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# Set custom learning rate for Adam optimizer\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the ANN with class weights and custom optimizer\n",
    "class_weight = {0: 1 / 7963, 1: 1 / 2037}  # Inverse frequency weights\n",
    "total = 1 / 7963 + 1 / 2037\n",
    "class_weight = {0: (1 / 7963) / total, 1: (1 / 2037) / total}  # Normalize\n",
    "classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "# Train the ANN with EarlyStopping and validation split\n",
    "classifier.fit(X_train, y_train, batch_size=batch_size, epochs=max_epochs, class_weight=class_weight, \n",
    "               validation_split=validation_split, callbacks=[early_stopping])\n",
    "\n",
    "# Predict on the test set (probabilities)\n",
    "y_pred_prob = classifier.predict(X_test)\n",
    "\n",
    "# Precision-Recall Curve for threshold optimization\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)  # Avoid division by zero\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Print optimal threshold with 3 decimal places\n",
    "print(f\"Optimal Threshold (based on max F1-Score): {optimal_threshold:.3f}\")\n",
    "\n",
    "# Set the threshold here (edit this value to test different thresholds, e.g., 0.5 or optimal_threshold)\n",
    "custom_threshold = 0.6  # Default set to optimal_threshold; change to any value between 0 and 1\n",
    "\n",
    "# Apply the custom threshold\n",
    "y_pred = (y_pred_prob > custom_threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "pr_auc = np.trapezoid(recall, precision)  # Using trapezoid instead of trapz\n",
    "\n",
    "# Display Confusion Matrix as a table (copy-paste compatible for Word)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_table = pd.DataFrame(cm, index=['Actual Stayed (0)', 'Actual Left (1)'], columns=['Predicted Stayed (0)', 'Predicted Left (1)'])\n",
    "print(cm_table.to_string())\n",
    "\n",
    "# Print metrics with 3 decimal places\n",
    "print(f\"\\nAccuracy: {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall: {rec:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"Specificity: {spec:.3f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.3f}\")\n",
    "\n",
    "# Display Threshold Table for 0.1 to 0.9 (copy-paste compatible for Word)\n",
    "print(\"\\nThreshold Table [0.1 - 0.9]:\")\n",
    "thresholds_table = []\n",
    "for thresh in np.arange(0.1, 1.0, 0.1):\n",
    "    y_pred_thresh = (y_pred_prob > thresh).astype(int)\n",
    "    prec_thresh = precision_score(y_test, y_pred_thresh)\n",
    "    rec_thresh = recall_score(y_test, y_pred_thresh)\n",
    "    f1_thresh = f1_score(y_test, y_pred_thresh)\n",
    "    thresholds_table.append([thresh, prec_thresh, rec_thresh, f1_thresh])\n",
    "\n",
    "thresholds_df = pd.DataFrame(thresholds_table, columns=['Threshold', 'Precision', 'Recall', 'F1-Score'])\n",
    "thresholds_df = thresholds_df.round(3)  # Round to 3 decimal places\n",
    "print(thresholds_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
